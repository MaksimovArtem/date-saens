{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0\n",
      "Epoch:  1\n",
      "Epoch:  2\n",
      "Epoch:  3\n",
      "Epoch:  4\n",
      "Epoch:  5\n",
      "Epoch:  6\n",
      "Epoch:  7\n",
      "Epoch:  8\n",
      "Epoch:  9\n",
      "Accuracy 0.89246154\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import pandas as pd\n",
    "train = pd.read_csv('train.csv', header = None)\n",
    "\n",
    "y_train = train.iloc[:, 0:1].copy()\n",
    "x_train = train.iloc[:, 1:785].copy()\n",
    "\n",
    "test = pd.read_csv('test.csv', header = None)\n",
    "\n",
    "y_test = test.iloc[:, 0:1].copy()\n",
    "x_test = test.iloc[:, 1:785].copy()\n",
    "\n",
    "#---------------------------------------\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "x_train = x_train.astype('float32')/255.\n",
    "x_test = x_test.astype('float32')/255.\n",
    "\n",
    "x_train = x_train.values.reshape((-1, 784))\n",
    "x_test = x_test.values.reshape((-1, 784))\n",
    "\n",
    "N, M = x_train.shape\n",
    "O = 1024\n",
    "P = 256\n",
    "T = 27\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10\n",
    "\n",
    "inp = tf.placeholder(shape=(None, M), dtype=tf.float32)\n",
    "out = tf.placeholder(shape=(None, T), dtype=tf.float32)\n",
    "\n",
    "weights1 = tf.Variable(tf.truncated_normal([M, O], stddev=np.sqrt(1/M)))\n",
    "bias1 = tf.Variable(tf.ones([O])/O)\n",
    "layer1 = tf.nn.relu(tf.matmul(inp, weights1) + bias1)\n",
    "\n",
    "weights2 = tf.Variable(tf.truncated_normal([O, P], stddev=np.sqrt(1/O)))\n",
    "bias2 = tf.Variable(tf.ones([P])/P)\n",
    "layer2 = tf.nn.relu(tf.matmul(layer1, weights2) + bias2)\n",
    "\n",
    "weights_output = tf.Variable(tf.truncated_normal([P, T], stddev=np.sqrt(1/P)))\n",
    "bias_output = tf.Variable(tf.ones([T])/T)\n",
    "evidence = tf.matmul(layer2, weights_output) + bias_output\n",
    "output = tf.nn.softmax(evidence)\n",
    "\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=evidence, labels= out)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "train_step = tf.train.RMSPropOptimizer(learning_rate).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(output, 1), tf.argmax(out, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "tf.summary.scalar(\"Cost\", cross_entropy)\n",
    "tf.summary.scalar(\"Accuracy\", accuracy)\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(training_epochs):\n",
    "            print(\"Epoch: \", epoch)\n",
    "            batch_count = int(N/batch_size)\n",
    "            for i in range(batch_count):\n",
    "                start, finish = batch_size*i, batch_size*(i+1)\n",
    "                batch_x, batch_y = x_train[start:finish, :], y_train[start:finish, :]\n",
    "                d = {inp: batch_x, out: batch_y}\n",
    "                _, summary = sess.run([train_step, summary_op], feed_dict=d)\n",
    "        print(\"Accuracy\", accuracy.eval(feed_dict={inp: x_test, out: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65000/65000 [==============================] - 20s 309us/step - loss: 0.9816 - acc: 0.7166\n",
      "Epoch 2/10\n",
      "65000/65000 [==============================] - 16s 240us/step - loss: 0.5630 - acc: 0.8308\n",
      "Epoch 3/10\n",
      "65000/65000 [==============================] - 16s 252us/step - loss: 0.4441 - acc: 0.8638\n",
      "Epoch 4/10\n",
      "65000/65000 [==============================] - 19s 296us/step - loss: 0.3814 - acc: 0.8804\n",
      "Epoch 5/10\n",
      "65000/65000 [==============================] - 20s 307us/step - loss: 0.3416 - acc: 0.8931\n",
      "Epoch 6/10\n",
      "65000/65000 [==============================] - 23s 359us/step - loss: 0.3138 - acc: 0.8997\n",
      "Epoch 7/10\n",
      "65000/65000 [==============================] - 25s 390us/step - loss: 0.2912 - acc: 0.9063\n",
      "Epoch 8/10\n",
      "65000/65000 [==============================] - 26s 404us/step - loss: 0.2739 - acc: 0.9123\n",
      "Epoch 9/10\n",
      "65000/65000 [==============================] - 28s 438us/step - loss: 0.2572 - acc: 0.9171\n",
      "Epoch 10/10\n",
      "65000/65000 [==============================] - 31s 469us/step - loss: 0.2435 - acc: 0.9190\n",
      "13000/13000 [==============================] - 4s 286us/step\n",
      "[0.3986142090879954, 0.8815384603463686]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import pandas as pd\n",
    "train = pd.read_csv('train.csv', header = None)\n",
    "\n",
    "y_train = train.iloc[:, 0:1].copy()\n",
    "x_train = train.iloc[:, 1:785].copy()\n",
    "\n",
    "test = pd.read_csv('test.csv', header = None)\n",
    "\n",
    "y_test = test.iloc[:, 0:1].copy()\n",
    "x_test = test.iloc[:, 1:785].copy()\n",
    "\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "x_train = x_train.astype('float32')/255.\n",
    "x_test = x_test.astype('float32')/255.\n",
    "\n",
    "x_train = x_train.values.reshape((-1, 784))\n",
    "x_test = x_test.values.reshape((-1, 784))\n",
    "\n",
    "N, M = x_train.shape\n",
    "O = 1024\n",
    "P = 256\n",
    "T = 27\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(P, activation='relu'))\n",
    "model.add(Dense(T, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=training_epochs, batch_size=batch_size)\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65000/65000 [==============================] - 24s 370us/step - loss: 0.9164 - acc: 0.7301\n",
      "Epoch 2/10\n",
      "65000/65000 [==============================] - 23s 355us/step - loss: 0.5151 - acc: 0.8427\n",
      "Epoch 3/10\n",
      "65000/65000 [==============================] - 26s 407us/step - loss: 0.4175 - acc: 0.8714\n",
      "Epoch 4/10\n",
      "65000/65000 [==============================] - 30s 458us/step - loss: 0.3707 - acc: 0.8835\n",
      "Epoch 5/10\n",
      "65000/65000 [==============================] - 33s 505us/step - loss: 0.3399 - acc: 0.8933\n",
      "Epoch 6/10\n",
      "65000/65000 [==============================] - 35s 531us/step - loss: 0.3155 - acc: 0.8994\n",
      "Epoch 7/10\n",
      "65000/65000 [==============================] - 38s 581us/step - loss: 0.2935 - acc: 0.9065\n",
      "Epoch 8/10\n",
      "65000/65000 [==============================] - 87s 1ms/step - loss: 0.2759 - acc: 0.9112\n",
      "Epoch 9/10\n",
      "65000/65000 [==============================] - 75s 1ms/step - loss: 0.2537 - acc: 0.9172\n",
      "Epoch 10/10\n",
      "65000/65000 [==============================] - 42s 640us/step - loss: 0.2408 - acc: 0.9206\n",
      "13000/13000 [==============================] - 5s 361us/step\n",
      "[0.4834602659711471, 0.8752307658012096]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import pandas as pd\n",
    "train = pd.read_csv('train.csv', header = None)\n",
    "\n",
    "y_train = train.iloc[:, 0:1].copy()\n",
    "x_train = train.iloc[:, 1:785].copy()\n",
    "\n",
    "test = pd.read_csv('test.csv', header = None)\n",
    "\n",
    "y_test = test.iloc[:, 0:1].copy()\n",
    "x_test = test.iloc[:, 1:785].copy()\n",
    "\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "x_train = x_train.astype('float32')/255.\n",
    "x_test = x_test.astype('float32')/255.\n",
    "\n",
    "x_train = x_train.values.reshape((-1, 784))\n",
    "x_test = x_test.values.reshape((-1, 784))\n",
    "\n",
    "N, M = x_train.shape\n",
    "O = 2048\n",
    "P = 512\n",
    "T = 27\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(P, activation='relu'))\n",
    "model.add(Dense(T, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=training_epochs, batch_size=batch_size)\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65000/65000 [==============================] - 26s 403us/step - loss: 0.9031 - acc: 0.7350\n",
      "Epoch 2/10\n",
      "65000/65000 [==============================] - 31s 479us/step - loss: 0.4983 - acc: 0.8468\n",
      "Epoch 3/10\n",
      "65000/65000 [==============================] - 28s 438us/step - loss: 0.3991 - acc: 0.8758\n",
      "Epoch 4/10\n",
      "65000/65000 [==============================] - 30s 455us/step - loss: 0.3548 - acc: 0.8884\n",
      "Epoch 5/10\n",
      "65000/65000 [==============================] - 32s 497us/step - loss: 0.3229 - acc: 0.8978\n",
      "Epoch 6/10\n",
      "65000/65000 [==============================] - 35s 538us/step - loss: 0.2990 - acc: 0.9036\n",
      "Epoch 7/10\n",
      "65000/65000 [==============================] - 38s 579us/step - loss: 0.2813 - acc: 0.9113\n",
      "Epoch 8/10\n",
      "65000/65000 [==============================] - 40s 620us/step - loss: 0.2613 - acc: 0.9154\n",
      "Epoch 9/10\n",
      "65000/65000 [==============================] - 43s 666us/step - loss: 0.2494 - acc: 0.9189\n",
      "Epoch 10/10\n",
      "65000/65000 [==============================] - 44s 671us/step - loss: 0.2361 - acc: 0.9232\n",
      "13000/13000 [==============================] - 5s 392us/step\n",
      "[0.42118706771960623, 0.8846153823228983]\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e6eee11cb972>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvis_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mSVG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'dot'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;31m#пакеты: graphviz, pydot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Lab3/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rankdir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Lab3/lib/python3.6/site-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpydot\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         raise ImportError(\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0;34m'Failed to import `pydot`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0;34m'Please install `pydot`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             'For example with `pip install pydot`.')\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import `pydot`. Please install `pydot`. For example with `pip install pydot`."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import pandas as pd\n",
    "train = pd.read_csv('train.csv', header = None)\n",
    "\n",
    "y_train = train.iloc[:, 0:1].copy()\n",
    "x_train = train.iloc[:, 1:785].copy()\n",
    "\n",
    "test = pd.read_csv('test.csv', header = None)\n",
    "\n",
    "y_test = test.iloc[:, 0:1].copy()\n",
    "x_test = test.iloc[:, 1:785].copy()\n",
    "\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "x_train = x_train.astype('float32')/255.\n",
    "x_test = x_test.astype('float32')/255.\n",
    "\n",
    "x_train = x_train.values.reshape((-1, 784))\n",
    "x_test = x_test.values.reshape((-1, 784))\n",
    "\n",
    "N, M = x_train.shape\n",
    "O = 1024\n",
    "P = 512\n",
    "T = 27\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(P, activation='relu'))\n",
    "model.add(Dense(T, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=training_epochs, batch_size=batch_size)\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print(score)\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model, show_shapes = True).create(prog = 'dot', format = 'svg'))\n",
    "#пакеты: graphviz, pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65000/65000 [==============================] - 24s 372us/step - loss: 0.9158 - acc: 0.7298\n",
      "Epoch 2/10\n",
      "65000/65000 [==============================] - 25s 388us/step - loss: 0.5183 - acc: 0.8422\n",
      "Epoch 3/10\n",
      "65000/65000 [==============================] - 27s 420us/step - loss: 0.4253 - acc: 0.8680\n",
      "Epoch 4/10\n",
      "65000/65000 [==============================] - 63s 969us/step - loss: 0.3782 - acc: 0.8833\n",
      "Epoch 5/10\n",
      "65000/65000 [==============================] - 73s 1ms/step - loss: 0.3542 - acc: 0.8893\n",
      "Epoch 6/10\n",
      "65000/65000 [==============================] - 33s 502us/step - loss: 0.3383 - acc: 0.8943\n",
      "Epoch 7/10\n",
      "65000/65000 [==============================] - 39s 604us/step - loss: 0.3181 - acc: 0.9011\n",
      "Epoch 8/10\n",
      "65000/65000 [==============================] - 39s 601us/step - loss: 0.3000 - acc: 0.9068\n",
      "Epoch 9/10\n",
      "65000/65000 [==============================] - 42s 650us/step - loss: 0.2909 - acc: 0.9097\n",
      "Epoch 10/10\n",
      "65000/65000 [==============================] - 45s 699us/step - loss: 0.2800 - acc: 0.9140\n",
      "13000/13000 [==============================] - 6s 463us/step\n",
      "[0.5109218238637998, 0.871923073896995]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import pandas as pd\n",
    "train = pd.read_csv('train.csv', header = None)\n",
    "\n",
    "y_train = train.iloc[:, 0:1].copy()\n",
    "x_train = train.iloc[:, 1:785].copy()\n",
    "\n",
    "test = pd.read_csv('test.csv', header = None)\n",
    "\n",
    "y_test = test.iloc[:, 0:1].copy()\n",
    "x_test = test.iloc[:, 1:785].copy()\n",
    "\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "x_train = x_train.astype('float32')/255.\n",
    "x_test = x_test.astype('float32')/255.\n",
    "\n",
    "x_train = x_train.values.reshape((-1, 784))\n",
    "x_test = x_test.values.reshape((-1, 784))\n",
    "\n",
    "N, M = x_train.shape\n",
    "O = 2048\n",
    "P = 512\n",
    "T = 27\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10\n",
    "\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "early_stopping = EarlyStopping(monitor = 'loss')\n",
    "tensorboard = TensorBoard(log_dir = './logs', write_graph = True)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(P, activation='relu'))\n",
    "model.add(Dense(T, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=training_epochs, batch_size=batch_size, callbacks = [early_stopping, tensorboard])\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-16-a9453bd05392>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-16-a9453bd05392>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    tensorboard --logdir =/logs\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#tensorboard --logdir =/logs#походу это в консоли -> PyCharm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "65000/65000 [==============================] - 74s 1ms/step - loss: 0.8602 - acc: 0.7587\n",
      "Epoch 2/10\n",
      "65000/65000 [==============================] - 80s 1ms/step - loss: 4.8178 - acc: 0.6276\n",
      "13000/13000 [==============================] - 8s 620us/step\n",
      "[10.334112064655011, 0.34884615586354184]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "import pandas as pd\n",
    "train = pd.read_csv('train.csv', header = None)\n",
    "\n",
    "y_train = train.iloc[:, 0:1].copy()\n",
    "x_train = train.iloc[:, 1:785].copy()\n",
    "\n",
    "test = pd.read_csv('test.csv', header = None)\n",
    "\n",
    "y_test = test.iloc[:, 0:1].copy()\n",
    "x_test = test.iloc[:, 1:785].copy()\n",
    "\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "\n",
    "x_train = x_train.astype('float32')/255.\n",
    "x_test = x_test.astype('float32')/255.\n",
    "\n",
    "x_train = x_train.values.reshape((-1, 784))\n",
    "x_test = x_test.values.reshape((-1, 784))\n",
    "\n",
    "N, M = x_train.shape\n",
    "O = 2048\n",
    "O1 = 1024\n",
    "P = 512\n",
    "P1 = 256\n",
    "T = 27\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10\n",
    "\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "early_stopping = EarlyStopping(monitor = 'loss')\n",
    "tensorboard = TensorBoard(log_dir = './logs', write_graph = True)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(O1, activation='relu'))\n",
    "model.add(Dense(P, activation='relu'))\n",
    "model.add(Dense(P1, activation='relu'))\n",
    "model.add(Dense(T, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=training_epochs, batch_size=batch_size, callbacks = [early_stopping, tensorboard])\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
